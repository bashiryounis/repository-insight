{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.settings import Settings\n",
    "from neo4j_graphrag.embeddings import SentenceTransformerEmbeddings\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j_graphrag.embeddings import OpenAIEmbeddings\n",
    "from neo4j_graphrag.retrievers import VectorCypherRetriever\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from pydantic import BaseModel, HttpUrl,Field\n",
    "from typing import List, Optional, Any\n",
    "from llama_index.core.program import LLMTextCompletionProgram\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from typing import Literal, Dict\n",
    "from llama_index.core.agent.workflow import AgentInput, AgentOutput, ToolCall, ToolCallResult, AgentStream\n",
    "from llama_index.core.workflow import Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_gemini = GoogleGenAI(model=\"gemini-1.5-pro\")\n",
    "llm_open= OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from neo4j import AsyncGraphDatabase\n",
    "\n",
    "NEO4J_USERNAME=\"neo4j\"\n",
    "NEO4J_PASSWORD=\"password\"\n",
    "NEO4J_URI=\"bolt://localhost:7687\"\n",
    "\n",
    "driver = AsyncGraphDatabase.driver(\n",
    "    NEO4J_URI, \n",
    "    auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    ")\n",
    "\n",
    "def get_session():\n",
    "    return driver.session()\n",
    "\n",
    "async def close_driver():\n",
    "    \"\"\"Closes the global Neo4j driver.\"\"\"\n",
    "    await driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "\n",
    "embed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "def get_embedding(text: str) -> list[float]:\n",
    "    if not text or not text.strip():\n",
    "        return []\n",
    "\n",
    "    embedding = embed_model.get_text_embedding(text)\n",
    "\n",
    "    if not isinstance(embedding, list):\n",
    "        try:\n",
    "            embedding = embedding.tolist()\n",
    "        except Exception as e:\n",
    "            return []\n",
    "\n",
    "    if not all(isinstance(x, (float, int)) and math.isfinite(x) for x in embedding):\n",
    "        return []\n",
    "\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovery  Agent  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def extract_node(node_name: str, node_label: Literal[\"File\", \"Folder\", \"Class\", \"Method\"]) -> Dict[str, str]:\n",
    "    \"\"\"Useful to extract exactly one repository entity from the user query.\"\"\"\n",
    "    return {\"node_label\": node_label, \"node_name\": node_name}\n",
    "\n",
    "\n",
    "async def search_graph(node_label: Literal[\"File\", \"Folder\", \"Class\", \"Method\"], node_name: str ) -> str :\n",
    "    \"\"\"Usefull to search for spacific node in Graph databse\"\"\"\n",
    "    top_k: int = 5\n",
    "    name_embedding = get_embedding(node_name)  \n",
    "\n",
    "    cypher = f\"\"\"\n",
    "    CALL db.index.vector.queryNodes('{node_label.lower()}_embedding_name_index', $top_k, $embedding)\n",
    "    YIELD node, score\n",
    "    {f\"WHERE '{node_label}' IN labels(node)\" if node_label else \"\"}\n",
    "    RETURN node.name AS name,node.description AS description,node.content AS content, score\n",
    "    ORDER BY score DESC\n",
    "    \"\"\"\n",
    "\n",
    "    async with get_session() as session:  # Assumes get_session can be used as context manager\n",
    "        result = await session.run(cypher, {\n",
    "            \"embedding\": name_embedding,\n",
    "            \"top_k\": top_k\n",
    "        })\n",
    "        records = [r async for r in result]\n",
    "\n",
    "    parts: List[str] = []\n",
    "    for r in records:\n",
    "        name = r[\"name\"]\n",
    "        desc = f\": {r['description']}\" if r.get(\"description\") else \"\"\n",
    "        content = r[\"content\"].rstrip()      # trim any trailing whitespace\n",
    "        parts.append(\n",
    "            f\"- **{name}**\\n\"\n",
    "            f\"**Description:** {desc}\\n\\n\"\n",
    "            f\"**Code:**\\n```\\n{content}\\n```\\n\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### ✅ ** `DISCOVERY_PROMPT`**\n",
    "DISCOVERY_PROMPT = \"\"\"\n",
    "You are DiscoveryAgent — an autonomous retrieval agent responsible for identifying and searching exactly one entity (File, Folder, Class, or Method) from a user's query and searching a graph database for relevant information.\n",
    "\n",
    "Your task is **not to answer the user directly**, but to **report your findings back to the PlannerAgent**, which will synthesize the final response.\n",
    "\n",
    "You have access to the following tools:\n",
    "\n",
    "1. **extract_node(node_name: str, node_label: Literal[\"File\", \"Folder\", \"Class\", \"Method\"])**\n",
    "   - Extracts a specific entity from the user's query.\n",
    "\n",
    "2. **search_graph(node_label: str, node_name: str)**\n",
    "   - Searches the graph database using the extracted node’s label and name.\n",
    "   - Returns relevant nodes, descriptions, and code snippets in markdown format.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 Workflow\n",
    "\n",
    "1. **Understand the Query:**\n",
    "   - Identify the most relevant entity (e.g., main.py, UserController, etc.).\n",
    "   - Determine the entity's type: \"File\", \"Folder\", \"Class\", or \"Method\".\n",
    "\n",
    "2. **Extract Entity:**\n",
    "   - Use extract_node with the selected name and type.\n",
    "\n",
    "3. **Search the Graph:**\n",
    "   - Use search_graph with **exact output** from extract_node.\n",
    "\n",
    "4. **Report Findings and Handoff:**\n",
    "   - Format your response to the **PlannerAgent** using this structure:[DiscoveryAgent Response]\n",
    "- **Entity**: `main.py` (Type: File)\n",
    "- **Reason**: Identified as the main file mentioned in the query.\n",
    "- **Search Results**:\n",
    "  - **Node**: main.py\n",
    "    **Score**: 0.98\n",
    "    **Description**: Entry point for the backend application.\n",
    "python\n",
    "    if __name__ == \"__main__\":\n",
    "        app.run()\n",
    "    Summary: This is the application entry point which launches the server.\n",
    "\n",
    "   - **After generating this report, hand off execution to the PlannerAgent.**\n",
    "\n",
    "---\n",
    "\n",
    "### 🔒 Strict Rules\n",
    "\n",
    "- **One entity only.**\n",
    "- **Always use extract_node before search_graph.**\n",
    "- **Use exact tool outputs.**\n",
    "- **Never invent facts — use only returned data.**\n",
    "- **Respond only to the PlannerAgent in the specified format.**\n",
    "- **Always hand off to the PlannerAgent after reporting your findings.**\n",
    "\n",
    "You are a specialist focused on retrieval. Report clean, structured results back to the planner so it can assemble the final answer and continue the conversation.\n",
    "\"\"\"\n",
    "\n",
    "discovery_agent = FunctionAgent(\n",
    "   name=\"DiscoveryAgent\",\n",
    "   description=\"DiscoveryAgent is an autonomous retrieval agent that identifies, extracts, and searches exactly one code entity (File, Folder, Class, or Method) from a query using a graph database. It reports its findings in a specific format *only* to the PlannerAgent and then hands off execution for further synthesis and user response.\",\n",
    "   tools=[extract_node, search_graph],\n",
    "   llm=llm_gemini,\n",
    "   system_prompt=DISCOVERY_PROMPT, # Use the updated prompt\n",
    "   can_handoff_to= [\"PlannerAgent\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation Resolver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_depend(filename: str, direction: Literal[\"out\", \"in\"]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Get full node objects of dependencies related to a given file.\"\"\"\n",
    "    if direction == \"out\":\n",
    "        cypher = \"\"\"\n",
    "        MATCH (f:File {name: $filename})-[:RELATED_TO]->(dep:File)\n",
    "        RETURN dep AS node\n",
    "        \"\"\"\n",
    "    else:\n",
    "        cypher = \"\"\"\n",
    "        MATCH (f:File {name: $filename})<-[:RELATED_TO]-(dep:File)\n",
    "        RETURN dep AS node\n",
    "        \"\"\"\n",
    "\n",
    "    async with get_session() as session:\n",
    "        result = await session.run(cypher, {\"filename\": filename.strip()})\n",
    "        records = [r async for r in result]\n",
    "\n",
    "    cleaned_nodes = []\n",
    "    for record in records:\n",
    "        node = record.values()[0]\n",
    "        if hasattr(node, \"items\"):\n",
    "            cleaned = {k: v for k, v in dict(node).items() if not k.startswith(\"embedding\")}\n",
    "            cleaned_nodes.append(cleaned)\n",
    "\n",
    "    return cleaned_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_node_relationships_by_label(\n",
    "    label: Literal[\"File\", \"Folder\", \"Class\", \"Method\"],\n",
    "    name: str,\n",
    "    direction: Literal[\"out\", \"in\", \"both\"],  \n",
    "    relationship_type: Literal[\"CONTAINS\", \"RELATED_TO\"],           \n",
    "):\n",
    "    \"\"\"Fetch relationships of a node with the given label and name.\n",
    "    Excludes any node properties that start with 'embedding'.\n",
    "    \"\"\"\n",
    "    limit = 25\n",
    "    rel_filter = f\":{relationship_type}\" if relationship_type else \"\"\n",
    "\n",
    "    if direction == \"out\":\n",
    "        cypher = f\"\"\"\n",
    "        MATCH (n:{label} {{name: $name}})-[r{rel_filter}]->(m)\n",
    "        RETURN type(r) AS rel_type, labels(m) AS target_labels, m AS target_node\n",
    "        LIMIT $limit\n",
    "        \"\"\"\n",
    "    elif direction == \"in\":\n",
    "        cypher = f\"\"\"\n",
    "        MATCH (m)-[r{rel_filter}]->(n:{label} {{name: $name}})\n",
    "        RETURN type(r) AS rel_type, labels(m) AS target_labels, m AS target_node\n",
    "        LIMIT $limit\n",
    "        \"\"\"\n",
    "    else:  # both\n",
    "        cypher = f\"\"\"\n",
    "        MATCH (n:{label} {{name: $name}})\n",
    "        OPTIONAL MATCH (n)-[r1{rel_filter}]->(m1)\n",
    "        OPTIONAL MATCH (m2)-[r2{rel_filter}]->(n)\n",
    "        RETURN \n",
    "            type(r1) AS out_rel, labels(m1) AS out_labels, m1 AS out_node,\n",
    "            type(r2) AS in_rel, labels(m2) AS in_labels, m2 AS in_node\n",
    "        LIMIT $limit\n",
    "        \"\"\"\n",
    "\n",
    "    async with get_session() as session:\n",
    "        result = await session.run(cypher, {\"name\": name, \"limit\": limit})\n",
    "        records = [record async for record in result] \n",
    "\n",
    "    relationships = []\n",
    "\n",
    "    for record in records:\n",
    "        if direction in (\"out\", \"both\") and record.get(\"out_rel\") and record.get(\"out_node\"):\n",
    "            node = {k: v for k, v in dict(record[\"out_node\"]).items() if not k.startswith(\"embedding\")}\n",
    "            relationships.append({\n",
    "                \"direction\": \"out\",\n",
    "                \"relationship_type\": record[\"out_rel\"],\n",
    "                \"target_labels\": record[\"out_labels\"],\n",
    "                \"target_node\": node,\n",
    "            })\n",
    "        if direction in (\"in\", \"both\") and record.get(\"in_rel\") and record.get(\"in_node\"):\n",
    "            node = {k: v for k, v in dict(record[\"in_node\"]).items() if not k.startswith(\"embedding\")}\n",
    "            relationships.append({\n",
    "                \"direction\": \"in\",\n",
    "                \"relationship_type\": record[\"in_rel\"],\n",
    "                \"target_labels\": record[\"in_labels\"],\n",
    "                \"target_node\": node,\n",
    "            })\n",
    "        if direction in (\"out\", \"in\") and record.get(\"rel_type\") and record.get(\"target_node\"):\n",
    "            node = {k: v for k, v in dict(record[\"target_node\"]).items() if not k.startswith(\"embedding\")}\n",
    "            relationships.append({\n",
    "                \"direction\": direction,\n",
    "                \"relationship_type\": record[\"rel_type\"],\n",
    "                \"target_labels\": record[\"target_labels\"],\n",
    "                \"target_node\": node,\n",
    "            })\n",
    "\n",
    "    return relationships\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def find_path_between_nodes_by_label(\n",
    "    start_label: Literal[\"File\", \"Folder\", \"Class\", \"Method\"],\n",
    "    start_name: str,\n",
    "    end_label: Literal[\"File\", \"Folder\", \"Class\", \"Method\"],\n",
    "    end_name: str,\n",
    "    relationship_filter: Literal[\"CONTAINS\", \"RELATED_TO\"],\n",
    "):\n",
    "    \"\"\"Finds the shortest path between two nodes via a specific relationship type and label.\"\"\"\n",
    "    max_depth = 5\n",
    "\n",
    "    # Relationship filter must be injected directly into the Cypher query\n",
    "    cypher = f\"\"\"\n",
    "    MATCH path = shortestPath(\n",
    "        (start:{start_label} {{name: $start_name}})-[:{relationship_filter}*..{max_depth}]-(end:{end_label} {{name: $end_name}})\n",
    "    )\n",
    "    RETURN nodes(path) AS nodes, relationships(path) AS relationships\n",
    "    \"\"\"\n",
    "\n",
    "    async with get_session() as session:\n",
    "        result = await session.run(cypher, {\n",
    "            \"start_name\": start_name,\n",
    "            \"end_name\": end_name\n",
    "        })\n",
    "        records = [record async for record in result]\n",
    "\n",
    "    paths = []\n",
    "    for record in records:\n",
    "        node_path = [\n",
    "            {k: v for k, v in dict(n).items() if not k.startswith(\"embedding\")}\n",
    "            for n in record[\"nodes\"]\n",
    "        ]\n",
    "        rel_path = [r.type for r in record[\"relationships\"]]\n",
    "        paths.append({\n",
    "            \"nodes\": node_path,\n",
    "            \"relationships\": rel_path\n",
    "        })\n",
    "\n",
    "    return paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_full_path_to_node(\n",
    "    target_label: Literal[\"File\", \"Folder\", \"Class\", \"Method\"],\n",
    "    target_name: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds the full hierarchical path (using :CONTAINS relationships)\n",
    "    from the root node labeled 'Repository' down to the specified target node.\n",
    "    \"\"\"\n",
    "    cypher = f\"\"\"\n",
    "    MATCH (root:Repository)\n",
    "    MATCH path = (root)-[:CONTAINS*]->(target:{target_label} {{name: $target_name}})\n",
    "    RETURN [n in nodes(path) | n.name] AS path_names // Return the list of node names in order\n",
    "    \"\"\"\n",
    "\n",
    "    async with get_session() as session:\n",
    "        result = await session.run(cypher, {\"target_name\": target_name})\n",
    "        records = await result.data()\n",
    "\n",
    "    paths_as_strings = []\n",
    "    for record in records:\n",
    "        path_names = record.get(\"path_names\")\n",
    "        if path_names:\n",
    "            paths_as_strings.append(\"/\".join(path_names))\n",
    "\n",
    "    return paths_as_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATION_PROMPT = \"\"\"\n",
    "You are the RelationResolverAgent, a specialized agent within a multi-agent system designed to resolve questions about relationships, dependencies, and structural hierarchies in a codebase represented as a graph database.\n",
    "\n",
    "Your mission is not to respond directly to the user, but to:\n",
    "- Interpret a relationship-related subtask delegated to you by the PlannerAgent.\n",
    "- Execute graph queries using the tools provided.\n",
    "- Return your synthesized results back to the PlannerAgent for final user-facing synthesis.\n",
    "\n",
    "You have access to the following tools:\n",
    "1. `get_depend(filename: str, direction: Literal[\"out\", \"in\", \"both\"])`: Finds files that a given file depends on (\"out\") or files that depend on the given file (\"in\") using 'RELATED_TO' relationships.\n",
    "\n",
    "2. `get_node_relationships_by_label(label: Literal[\"File\", \"Folder\", \"Class\", \"Method\"], name: str, direction: Literal[\"out\", \"in\", \"both\"], relationship_type: Literal[\"CONTAINS\",\"RELATED_TO\"])`: Gets direct one-hop relationships for the given node.\n",
    "\n",
    "3. `find_path_between_nodes_by_label(start_label: Literal[\"File\", \"Folder\", \"Class\", \"Method\"], start_name: str, end_label: Literal[\"File\", \"Folder\", \"Class\", \"Method\"], end_name: str, relationship_filter: Literal[\"CONTAINS\",\"RELATED_TO\"])`: Finds shortest paths between two entities.\n",
    "\n",
    "4. `get_full_path_to_node(target_label: Literal[\"File\", \"Folder\", \"Class\", \"Method\"], target_name: str)`: Finds the full hierarchical path from the Repository root to the given node.\n",
    "\n",
    "Workflow:\n",
    "1. **Analyze the user's query** as delegated from the Planner. Understand if it’s about:\n",
    "   - Dependencies (\"depends on\", \"used by\", \"imports\", etc.)\n",
    "   - Containment or structure (\"inside\", \"parent folder\", \"full path\", etc.)\n",
    "   - Connections (\"path between\", \"related to\", \"calls\", etc.)\n",
    "\n",
    "2. **Identify the involved node(s)** — label and name — from the Planner’s handoff.\n",
    "\n",
    "3. **Choose the correct tool(s)**:\n",
    "   - Use `get_full_path_to_node` for \"full path\" or structural location.\n",
    "   - Use `find_path_between_nodes_by_label` for paths between two nodes.\n",
    "   - Use `get_depend` for file-level dependencies.\n",
    "   - Use `get_node_relationships_by_label` for other local or class-level connections.\n",
    "\n",
    "   For Class or Method dependency questions:\n",
    "   - **Step 1:** Use `get_node_relationships_by_label` with direction=\"out\".\n",
    "   - **Step 2:** Use `get_node_relationships_by_label` with direction=\"in\", relationship_type=\"CONTAINS\" to find the containing File.\n",
    "   - **Step 3:** If a containing file is found, use `get_depend` on that file (direction=\"out\").\n",
    "\n",
    "4. **Execute the graph queries** with correct parameters.\n",
    "\n",
    "5. **Interpret and combine results** clearly:\n",
    "   - If combining direct and file-level dependencies, label them accordingly.\n",
    "   - Format paths, relationships, or hierarchies in readable bullet or step form.\n",
    "   - Avoid duplication and filter irrelevant noise.\n",
    "   - If no data is found, return a meaningful message (e.g., \"No dependencies found for X\").\n",
    "\n",
    "6. **Do NOT reply directly to the user.**\n",
    "   - Instead, hand off the final synthesized answer using:\n",
    "     `handoff(\"PlannerAgent\", response=\"<your_final_answer_here>\")`\n",
    "\n",
    "7. **Do NOT perform further reasoning after handoff.** Wait for PlannerAgent to handle any follow-up.\n",
    "\n",
    "Example Flows:\n",
    "- Query: “What does `main.py` depend on?”\n",
    "   → Get dependents using `get_depend(\"main.py\", direction=\"out\")`\n",
    "   → Return dependencies via `handoff(PlannerAgent, response=...)`\n",
    "\n",
    "- Query: “What’s the full path to `main.py`?”\n",
    "   → Use `get_full_path_to_node(label=\"File\", name=\"main.py\")`\n",
    "   → Return path string via handoff\n",
    "\n",
    "- Query: “What’s the relationship between `main.py` and `config` folder?”\n",
    "   → Use `find_path_between_nodes_by_label(...)`\n",
    "   → Return path/connection details via handoff\n",
    "\n",
    "Be factual, concise, and helpful. Your only output should be a well-written string summarizing what was found, then immediately handed off to the PlannerAgent.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# The relre_agent definition remains the same, only the system_prompt is updated\n",
    "relre_agent = FunctionAgent(\n",
    "   name=\"RelationResolverAgent\",\n",
    "   description=\"Resolves dependencies, relationships, and structural paths between entities in the codebase graph, and hands the results back to the PlannerAgent for final response synthesis.\",\n",
    "   tools=[find_path_between_nodes_by_label, get_node_relationships_by_label, get_depend, get_full_path_to_node],\n",
    "   llm=llm_gemini, \n",
    "   system_prompt=RELATION_PROMPT,\n",
    "   can_handoff_to=[\"PlannerAgent\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/younis/miniconda3/envs/llamaindex/lib/python3.12/site-packages/llama_index/core/workflow/events.py:68: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  if k in self.model_fields:\n"
     ]
    }
   ],
   "source": [
    "response = await relre_agent.run(\"what main.py file depend on ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/younis/miniconda3/envs/llamaindex/lib/python3.12/site-packages/llama_index/core/workflow/events.py:81: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  if __name in self.__private_attributes__ or __name in self.model_fields:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text='')]), tool_calls=[ToolCallResult(tool_name='get_depend', tool_kwargs={'filename': 'main.py', 'direction': 'out'}, tool_id='get_depend', tool_output=ToolOutput(content='[{\\'summary\\': \\'This module provides utility functions for handling image files and processing delivery images using OCR. It includes functions for saving images, loading images, and performing OCR on delivery images using a generative AI model. The module also defines asynchronous functions for saving files.\\', \\'path\\': \\'delivery-ocr/api/src/service/utils.py\\', \\'name\\': \\'utils.py\\', \\'description\\': \\'This file defines functions for handling image files, specifically for processing delivery images using OCR (Optical Character Recognition). It includes functions for saving images (both synchronously and asynchronously), loading images, and processing delivery images to extract information. The core functionality revolves around saving uploaded image files, loading them, and then using a generative AI model to extract a delivery summary based on a predefined prompt. The `process_delivery_image` function orchestrates the entire OCR pipeline, from saving the image to extracting and returning the delivery summary.\\\\n\\', \\'parent_path\\': \\'delivery-ocr/api/src/service\\', \\'content\\': \\'import os\\\\nimport shutil\\\\nimport aiofiles\\\\nimport asyncio\\\\nimport logging\\\\nfrom PIL import Image\\\\nfrom fastapi import  UploadFile\\\\nfrom src.core.config import config \\\\nfrom src.core.prompt import DELIVERY_PROMPT\\\\nfrom src.core.llm import genai_client\\\\nfrom src.core.schema import DeliverySummary\\\\n\\\\n# ----------------------------------------\\\\n\\\\ndef load_image(image_path):\\\\n    return Image.open(image_path)\\\\n\\\\ndef save_image(image_path, output_path):\\\\n    image = load_image(image_path)\\\\n    image.save(output_path)\\\\n    return output_path\\\\n\\\\ndef save_file(file: UploadFile) -> str:\\\\n    \"\"\"save file in the specified directory.\"\"\"\\\\n    \\\\n    file_path = os.path.join(config.MAIN_DIR, file.filename)\\\\n    with open(file_path, \"wb\") as buffer:\\\\n        shutil.copyfileobj(file.file, buffer)\\\\n    \\\\n    return file_path\\\\n\\\\nasync def save_file_async(file: UploadFile) -> str:\\\\n    \"\"\"Save uploaded file asynchronously to MAIN_DIR.\"\"\"\\\\n    os.makedirs(config.MAIN_DIR, exist_ok=True)\\\\n    path = os.path.join(config.MAIN_DIR, file.filename)\\\\n\\\\n    async with aiofiles.open(path, \"wb\") as out_file:\\\\n        while chunk := await file.read(1024 * 64):\\\\n            await out_file.write(chunk)\\\\n    return path\\\\n\\\\nasync def process_delivery_image(file: UploadFile) -> DeliverySummary:\\\\n    \"\"\"Handles full OCR pipeline: save, load, extract.\"\"\"\\\\n    image_path = await save_file_async(file)\\\\n    image = load_image(image_path)\\\\n    response = genai_client.models.generate_content(\\\\n        model = config.GENERATIVE_MODEL,\\\\n        contents = [DELIVERY_PROMPT, image],\\\\n        config={\\\\n            \\\\\\'response_schema\\\\\\': DeliverySummary,\\\\n            \\\\\\'response_mime_type\\\\\\': \\\\\\'application/json\\\\\\'\\\\n        })\\\\n    return response.parsed\\', \\'node_id\\': \\'eac71f36-0d26-511d-a5c4-f06eb5692aec\\'}, {\\'summary\\': \\'This code defines an API endpoint `/delivery` that uses OCR to extract delivery information from an uploaded image file. It processes the image using the `process_delivery_image` function and returns the extracted data. It handles exceptions and logs the process.\\', \\'path\\': \\'delivery-ocr/api/src/service/ocr_delivery.py\\', \\'name\\': \\'ocr_delivery.py\\', \\'description\\': \\'This code defines an API endpoint `/delivery` using FastAPI that performs OCR on uploaded delivery images. It extracts delivery information from the image using the `process_delivery_image` function and returns the extracted data as a JSON response. The endpoint handles file uploads, logs requests and processing results, and includes error handling to return appropriate HTTP exceptions in case of failures.\\\\n\\', \\'parent_path\\': \\'delivery-ocr/api/src/service\\', \\'content\\': \\'import json\\\\nfrom fastapi import APIRouter, HTTPException, Depends , Request , Header, File, UploadFile\\\\nfrom src.service.utils import process_delivery_image \\\\nimport logging \\\\n\\\\nlogger = logging.getLogger(__name__)\\\\nrouter = APIRouter()\\\\n\\\\n@router.post(\"/delivery\")\\\\nasync def delivery_ocr(file: UploadFile = File(...)):\\\\n    \"\"\"Extract delivery information from an uploaded image.\"\"\"\\\\n    logger.info(f\"Received delivery OCR request for file: {file.filename}\")\\\\n    try:\\\\n        extracted_data = await process_delivery_image(file)\\\\n        logger.info(f\"Extraction successful for file: {file.filename}\")\\\\n        return {\"extracted_data\": extracted_data.model_dump()}\\\\n    except Exception as e:\\\\n        logger.exception(f\"OCR processing failed for {file.filename}: {e}\")\\\\n        raise HTTPException(status_code=500, detail=f\"OCR processing failed: {str(e)}\")\\\\n\\', \\'node_id\\': \\'36f4cc76-94ef-59f3-acfa-f4890c880ba0\\'}, {\\'path\\': \\'delivery-ocr/api/src/core/logger_config.py\\', \\'name\\': \\'logger_config.py\\', \\'parent_path\\': \\'delivery-ocr/api/src/core\\', \\'content\\': \\'import logging.config\\\\n\\\\nLOGGING_CONFIG = {\\\\n    \"version\": 1,\\\\n    \"disable_existing_loggers\": False,\\\\n    \"formatters\": {\\\\n        \"default\": {\\\\n            \"format\": \"[%(asctime)s] %(levelname)s in %(module)s: %(message)s\",\\\\n        },\\\\n        \"detailed\": {\\\\n            \"format\": \"[%(asctime)s] %(levelname)s [%(name)s:%(lineno)d] %(message)s\",\\\\n        },\\\\n    },\\\\n    \"handlers\": {\\\\n        \"console\": {\\\\n            \"class\": \"logging.StreamHandler\",\\\\n            \"formatter\": \"default\",\\\\n            \"level\": \"INFO\",\\\\n        },\\\\n        \"file\": {\\\\n            \"class\": \"logging.FileHandler\",\\\\n            \"filename\": \"app.log\",\\\\n            \"formatter\": \"detailed\",\\\\n            \"level\": \"INFO\",\\\\n        },\\\\n    },\\\\n    \"loggers\": {\\\\n        \"\": {  # root logger\\\\n            \"handlers\": [\"console\", \"file\"],\\\\n            \"level\": \"INFO\",\\\\n        },\\\\n        \"uvicorn.error\": {\\\\n            \"level\": \"INFO\",\\\\n            \"handlers\": [\"console\", \"file\"],\\\\n            \"propagate\": False,\\\\n        },\\\\n        \"uvicorn.access\": {\\\\n            \"level\": \"INFO\",\\\\n            \"handlers\": [\"console\", \"file\"],\\\\n            \"propagate\": False,\\\\n        },\\\\n    },\\\\n}\\\\n\\\\ndef setup_logging():\\\\n    logging.config.dictConfig(LOGGING_CONFIG)\\', \\'node_id\\': \\'4a5fc58c-1647-559b-9ffd-b3f4437f1685\\'}]', tool_name='get_depend', raw_input={'args': (), 'kwargs': {'filename': 'main.py', 'direction': 'out'}}, raw_output=[{'summary': 'This module provides utility functions for handling image files and processing delivery images using OCR. It includes functions for saving images, loading images, and performing OCR on delivery images using a generative AI model. The module also defines asynchronous functions for saving files.', 'path': 'delivery-ocr/api/src/service/utils.py', 'name': 'utils.py', 'description': 'This file defines functions for handling image files, specifically for processing delivery images using OCR (Optical Character Recognition). It includes functions for saving images (both synchronously and asynchronously), loading images, and processing delivery images to extract information. The core functionality revolves around saving uploaded image files, loading them, and then using a generative AI model to extract a delivery summary based on a predefined prompt. The `process_delivery_image` function orchestrates the entire OCR pipeline, from saving the image to extracting and returning the delivery summary.\\n', 'parent_path': 'delivery-ocr/api/src/service', 'content': 'import os\\nimport shutil\\nimport aiofiles\\nimport asyncio\\nimport logging\\nfrom PIL import Image\\nfrom fastapi import  UploadFile\\nfrom src.core.config import config \\nfrom src.core.prompt import DELIVERY_PROMPT\\nfrom src.core.llm import genai_client\\nfrom src.core.schema import DeliverySummary\\n\\n# ----------------------------------------\\n\\ndef load_image(image_path):\\n    return Image.open(image_path)\\n\\ndef save_image(image_path, output_path):\\n    image = load_image(image_path)\\n    image.save(output_path)\\n    return output_path\\n\\ndef save_file(file: UploadFile) -> str:\\n    \"\"\"save file in the specified directory.\"\"\"\\n    \\n    file_path = os.path.join(config.MAIN_DIR, file.filename)\\n    with open(file_path, \"wb\") as buffer:\\n        shutil.copyfileobj(file.file, buffer)\\n    \\n    return file_path\\n\\nasync def save_file_async(file: UploadFile) -> str:\\n    \"\"\"Save uploaded file asynchronously to MAIN_DIR.\"\"\"\\n    os.makedirs(config.MAIN_DIR, exist_ok=True)\\n    path = os.path.join(config.MAIN_DIR, file.filename)\\n\\n    async with aiofiles.open(path, \"wb\") as out_file:\\n        while chunk := await file.read(1024 * 64):\\n            await out_file.write(chunk)\\n    return path\\n\\nasync def process_delivery_image(file: UploadFile) -> DeliverySummary:\\n    \"\"\"Handles full OCR pipeline: save, load, extract.\"\"\"\\n    image_path = await save_file_async(file)\\n    image = load_image(image_path)\\n    response = genai_client.models.generate_content(\\n        model = config.GENERATIVE_MODEL,\\n        contents = [DELIVERY_PROMPT, image],\\n        config={\\n            \\'response_schema\\': DeliverySummary,\\n            \\'response_mime_type\\': \\'application/json\\'\\n        })\\n    return response.parsed', 'node_id': 'eac71f36-0d26-511d-a5c4-f06eb5692aec'}, {'summary': 'This code defines an API endpoint `/delivery` that uses OCR to extract delivery information from an uploaded image file. It processes the image using the `process_delivery_image` function and returns the extracted data. It handles exceptions and logs the process.', 'path': 'delivery-ocr/api/src/service/ocr_delivery.py', 'name': 'ocr_delivery.py', 'description': 'This code defines an API endpoint `/delivery` using FastAPI that performs OCR on uploaded delivery images. It extracts delivery information from the image using the `process_delivery_image` function and returns the extracted data as a JSON response. The endpoint handles file uploads, logs requests and processing results, and includes error handling to return appropriate HTTP exceptions in case of failures.\\n', 'parent_path': 'delivery-ocr/api/src/service', 'content': 'import json\\nfrom fastapi import APIRouter, HTTPException, Depends , Request , Header, File, UploadFile\\nfrom src.service.utils import process_delivery_image \\nimport logging \\n\\nlogger = logging.getLogger(__name__)\\nrouter = APIRouter()\\n\\n@router.post(\"/delivery\")\\nasync def delivery_ocr(file: UploadFile = File(...)):\\n    \"\"\"Extract delivery information from an uploaded image.\"\"\"\\n    logger.info(f\"Received delivery OCR request for file: {file.filename}\")\\n    try:\\n        extracted_data = await process_delivery_image(file)\\n        logger.info(f\"Extraction successful for file: {file.filename}\")\\n        return {\"extracted_data\": extracted_data.model_dump()}\\n    except Exception as e:\\n        logger.exception(f\"OCR processing failed for {file.filename}: {e}\")\\n        raise HTTPException(status_code=500, detail=f\"OCR processing failed: {str(e)}\")\\n', 'node_id': '36f4cc76-94ef-59f3-acfa-f4890c880ba0'}, {'path': 'delivery-ocr/api/src/core/logger_config.py', 'name': 'logger_config.py', 'parent_path': 'delivery-ocr/api/src/core', 'content': 'import logging.config\\n\\nLOGGING_CONFIG = {\\n    \"version\": 1,\\n    \"disable_existing_loggers\": False,\\n    \"formatters\": {\\n        \"default\": {\\n            \"format\": \"[%(asctime)s] %(levelname)s in %(module)s: %(message)s\",\\n        },\\n        \"detailed\": {\\n            \"format\": \"[%(asctime)s] %(levelname)s [%(name)s:%(lineno)d] %(message)s\",\\n        },\\n    },\\n    \"handlers\": {\\n        \"console\": {\\n            \"class\": \"logging.StreamHandler\",\\n            \"formatter\": \"default\",\\n            \"level\": \"INFO\",\\n        },\\n        \"file\": {\\n            \"class\": \"logging.FileHandler\",\\n            \"filename\": \"app.log\",\\n            \"formatter\": \"detailed\",\\n            \"level\": \"INFO\",\\n        },\\n    },\\n    \"loggers\": {\\n        \"\": {  # root logger\\n            \"handlers\": [\"console\", \"file\"],\\n            \"level\": \"INFO\",\\n        },\\n        \"uvicorn.error\": {\\n            \"level\": \"INFO\",\\n            \"handlers\": [\"console\", \"file\"],\\n            \"propagate\": False,\\n        },\\n        \"uvicorn.access\": {\\n            \"level\": \"INFO\",\\n            \"handlers\": [\"console\", \"file\"],\\n            \"propagate\": False,\\n        },\\n    },\\n}\\n\\ndef setup_logging():\\n    logging.config.dictConfig(LOGGING_CONFIG)', 'node_id': '4a5fc58c-1647-559b-9ffd-b3f4437f1685'}], is_error=False), return_direct=False)], raw={'content': {'parts': [{'video_metadata': None, 'thought': None, 'code_execution_result': None, 'executable_code': None, 'file_data': None, 'function_call': None, 'function_response': None, 'inline_data': None, 'text': ''}], 'role': 'model'}, 'citation_metadata': None, 'finish_message': None, 'token_count': None, 'avg_logprobs': None, 'finish_reason': <FinishReason.STOP: 'STOP'>, 'grounding_metadata': None, 'index': None, 'logprobs_result': None, 'safety_ratings': None, 'usage_metadata': {'cached_content_token_count': None, 'candidates_token_count': None, 'prompt_token_count': 2955, 'total_token_count': 2955}}, current_agent_name='RelationResolverAgent')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal # Make sure Literal is imported\n",
    "\n",
    "async def similarity_search( node_label: Literal[\"File\", \"Class\", \"Method\"], query: str):\n",
    "    \"\"\"\n",
    "    Searches the code graph for nodes (Files, Classes, or Methods)\n",
    "    semantically similar to the query using vector embeddings.\n",
    "    Searches within both description and content fields.\n",
    "    Returns the top_k most relevant nodes and their scores.\n",
    "    \"\"\"\n",
    "    top_k=5 \n",
    "    embedding = get_embedding(query) # If get_embedding is sync and blocking, this is a problem\n",
    "\n",
    "\n",
    "    indexes = [\n",
    "        f\"{node_label.lower()}_embedding_description_index\",\n",
    "        f\"{node_label.lower()}_embedding_content_index\"\n",
    "    ]\n",
    "\n",
    "    combined_results = []\n",
    "\n",
    "    async with get_session() as session:\n",
    "        for index in indexes:\n",
    "            cypher = \"\"\"\n",
    "            CALL db.index.vector.queryNodes($index_name, $top_k, $embedding)\n",
    "            YIELD node, score\n",
    "            RETURN node.name AS name,\n",
    "                   node.description AS description,\n",
    "                   node.content AS content,\n",
    "                   labels(node) AS labels,\n",
    "                   score\n",
    "            ORDER BY score DESC\n",
    "            \"\"\"\n",
    "            # Use the 'session' obtained from the 'async with' block\n",
    "            result = await session.run(cypher, {\n",
    "                \"index_name\": index,\n",
    "                \"embedding\": embedding,\n",
    "                \"top_k\": top_k # Use the local top_k variable\n",
    "            })\n",
    "\n",
    "            # Correctly iterate over the async result cursor\n",
    "            combined_results.extend([record async for record in result])\n",
    "\n",
    "    seen = set()\n",
    "    deduped = []\n",
    "    # Sort the combined results by score (highest first) before deduplicating and truncating\n",
    "    for record in sorted(combined_results, key=lambda r: r[\"score\"], reverse=True):\n",
    "        key = record.get(\"name\") # Use get(\"name\") as it's explicitly returned\n",
    "        if key and key not in seen:\n",
    "            seen.add(key)\n",
    "            deduped.append(record)\n",
    "        elif not key:\n",
    "             deduped.append(record) \n",
    "\n",
    "    return deduped[:top_k]\n",
    "\n",
    "\n",
    "\n",
    "RESEARCH_PROMPT=\"\"\"\n",
    "You are the ResearcherAgent, an expert in navigating and searching a codebase represented as a graph database.\n",
    "Your primary function is to find specific code elements (Files, Classes, or Methods) relevant to a user's query using semantic search.\n",
    "\n",
    "Your ONLY tool is `similarity_search`.\n",
    "\n",
    "Tool:\n",
    "`similarity_search(node_label: Literal[\"File\", \"Class\", \"Method\"], query: str)`\n",
    "Description: Performs a vector similarity search against nodes of the specified type (File, Class, or Method) using the provided natural language query. It searches both the semantic description and content embeddings. Returns a list of the most relevant nodes found, ordered by relevance score.\n",
    "\n",
    "Your Workflow:\n",
    "Your Workflow:\n",
    "1.  Analyze the user's query carefully to understand the intent.\n",
    "2.  **Crucially, classify the user's intent to determine the MOST appropriate `node_label`** for the `similarity_search` tool.\n",
    "    * If the user asks about a specific file or content *within* a file (\"find the file that...\", \"what file contains...\", \"show me the code in file X\"), choose `node_label=\"File\"`.\n",
    "    * If the user asks about a class definition, purpose, or how a class is used (\"what is class Y\", \"definition of class Z\", \"how does Class A work\"), choose `node_label=\"Class\"`.\n",
    "    * If the user asks about a specific method/function, its implementation details, or how to perform an action (\"how to call method M\", \"implementation of function F\", \"show me method N\"), choose `node_label=\"Method\"`.\n",
    "    * If the query is general, try to infer the most likely target. Make your best guess based on keywords. **You must select exactly one label.**\n",
    "3.  Formulate a clear and concise `query` string to pass to the `similarity_search` tool. This query should capture the essence of what the user is looking for. You can refine the user's original phrasing slightly for better search results.\n",
    "4.  Call the `similarity_search` tool with the chosen `node_label` and the formulated `query`.\n",
    "5.  Process the results returned by the tool.\n",
    "    * Identify the most promising results based on their `score`.\n",
    "    * Prepare a structured report of your findings.\n",
    "    * **For each relevant result, include:**\n",
    "        * `name`\n",
    "        * `score`\n",
    "        * `description` (if it exists)\n",
    "        * `content` (if it exists - this is the code/longer text)\n",
    "        * `labels`\n",
    "    * If no results are returned by the tool, state clearly that no relevant results were found for the query under the chosen label.\n",
    "6.  **ALWAYS** hand off to the `PlannerAgent` after completing the search and preparing your report. Your role is research; the PlannerAgent is responsible for synthesizing the information and formulating the final user-facing response or planning the next steps.\n",
    "7.  **Your output MUST be formatted ONLY for the PlannerAgent.** Present the search results clearly in a structured format (e.g., a list of dictionaries or a similar readable structure) followed by the handoff command.\n",
    "\n",
    "Example Handoff Format (After Tool Call):\n",
    "ResearcherAgent (Handoff):\n",
    "Research Complete. Found the following results:\n",
    "[\n",
    "  {{ \"name\": \"AuthService.py\", \"score\": 0.85, \"description\": \"Handles user authentication flows.\", \"content\": \"import hashlib...\", \"labels\": [\"File\", \"Method\"] }},\n",
    "  {{ \"name\": \"UserRepository.java\", \"score\": 0.70, \"description\": \"Manages user data and persistence.\", \"content\": \"public class UserRepository { ... }\", \"labels\": [\"Class\", \"File\"] }}\n",
    "]\n",
    "Handing off to PlannerAgent to process these results.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "research_agent = FunctionAgent(\n",
    "   name=\"ResearcherAgent\",\n",
    "   description=\"Researches the codebase using semantic search based on user queries. Analyzes queries to search relevant Files, Classes, or Methods. It reports its findings, including relevant descriptions and potentially code or content snippets, in a specific format *only* to the PlannerAgent and then hands off execution for further synthesis and user response.\",\n",
    "   tools=[similarity_search],\n",
    "   llm=llm_gemini,\n",
    "   system_prompt=RESEARCH_PROMPT,\n",
    "   can_handoff_to= [\"PlannerAgent\"] \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planner Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLANNER_PROMPT = \"\"\"\n",
    "You are the Planner Agent — the reasoning and coordination core of a multi-agent system that answers user questions about a codebase indexed in a graph database.\n",
    "\n",
    "Your role:\n",
    "- Analyze the user’s query and understand its intent.\n",
    "- Decompose the query into one or more precise, meaningful subtasks.\n",
    "- Delegate these subtasks to the appropriate specialized agents.\n",
    "- Verify intermediate results before proceeding.\n",
    "- Synthesize and deliver a complete, accurate, and well-structured response, including relevant code examples where helpful for explaining code functionality.\n",
    "\n",
    "Agents you can delegate to:\n",
    "1. **DiscoveryAgent**\n",
    "   - Use when the query mentions a specific entity such as a file (e.g., `main.py`), folder (e.g., `backend`), class, or method, and you need to **locate or get basic details/content** about that entity.\n",
    "\n",
    "2. **RelationResolverAgent**\n",
    "   - Use when the query asks about the **relationship, connection, dependency, or structural path** involving one or more entities.\n",
    "   - This includes questions like:\n",
    "     - “How is X related to Y?”\n",
    "     - “What does X depend on?”\n",
    "     - “Which entities depend on Y?”\n",
    "     - “What is the **full path** to Z?”\n",
    "     - “What is the structure/hierarchy within folder A?”\n",
    "   - This agent requires the relevant entity/entities to be known and validated before delegation.\n",
    "\n",
    "3. **ResearcherAgent** (QA Agent)\n",
    "   - Use when the query is general, fuzzy, or conceptual, and does **not** name any specific file, folder, class, or method as the primary subject asking about its *relationships*, *content*, or *basic existence*.\n",
    "   - Use **only** when the query is about a general topic (e.g., “How is logging handled?”) OR when the user asks for a higher-level summary/purpose of an *already found* entity, and Discovery's basic description/content is insufficient.\n",
    "\n",
    "Reasoning process:\n",
    "- **Crucial Rule:** First, identify if the query mentions any specific entities (File, Folder, Class, Method).\n",
    "- **If specific entities are mentioned:**\n",
    "    - **Always** use the `DiscoveryAgent` to locate and verify **all** mentioned entities first.\n",
    "    - If any mentioned entity is NOT found by Discovery, stop processing that query part and inform the user which entity was not found.\n",
    "    - If **all** mentioned entities are found:\n",
    "        - Re-evaluate the original query intent based on the *found* entities.\n",
    "\n",
    "        - If the core question is about the **relationship, connection, dependency, or structural path** involving these entities (including asking for a \"full path\" to one of them), delegate the *specific relationship/path task* to the `RelationResolverAgent`. \n",
    "            - ⚠️ **Important**: Do NOT try to infer relationships or paths yourself from Discovery results — that is the RelationResolverAgent’s job.\n",
    "\n",
    "        - If the core question is about the **general purpose or conceptual role** of one of the found entities, and Discovery's information is insufficient, delegate to the `ResearcherAgent`.\n",
    "\n",
    "        - If the core question was simply to **find the entity and get its basic details/content**, use the results directly from Discovery.\n",
    "\n",
    "- **If NO specific entities are mentioned:**\n",
    "    - Proceed directly to general research/QA using the `ResearcherAgent`.\n",
    "\n",
    "- ✅ For queries like “What does X depend on?” or “What is the relationship between X and Y?”:\n",
    "    - First locate X (and Y if applicable) using DiscoveryAgent.\n",
    "    - Then, **always follow up** with RelationResolverAgent to answer the dependency or relationship part.\n",
    "    - Never return just the Discovery result for such questions — it’s not enough.\n",
    "\n",
    "- Never assume entities exist — verify through extraction before delegating tasks that depend on those entities being found.\n",
    "- Never skip a step or respond with partial results unless an entity was not found.\n",
    "\n",
    "Communication:\n",
    "- When acknowledging a query and outlining the plan *to the user*, provide a high-level description of the steps using action verbs (e.g., \"Searching for the requested file,\" \"Analyzing its content,\" \"Investigating the relationship,\" \"Determining the full location\"). Avoid mentioning specific agent names.\n",
    "- Report your internal reasoning and decisions clearly in the agent's *internal* thought process logs.\n",
    "- Synthesize the final response comprehensively, combining information obtained from the relevant agents.\n",
    "\n",
    "Examples:\n",
    "\n",
    "1. **Query**: \"What is the purpose of `main.py`?\"\n",
    "   - **Plan for user**: Okay, I understand the query. I will search to locate the `main.py` file and then analyze its content and description to determine its purpose.\n",
    "   - **Internal steps**: Use DiscoveryAgent to find `main.py`. If found, use Discovery's description/content. If deeper understanding is needed, call ResearcherAgent for analysis.\n",
    "\n",
    "2. **Query**: \"How is logging handled?\"\n",
    "   - **Plan for user**: Okay, I understand the query. I will research how logging is handled in the codebase.\n",
    "   - **Internal steps**: Use ResearcherAgent (QA) since no specific entity is the subject.\n",
    "\n",
    "3. **Query**: \"What’s the relation between `main.py` and the `backend` folder?\"\n",
    "   - **Plan for user**: Okay, I understand the query. I will first search to locate `main.py` and the `backend` folder, and then investigate the relationship between them.\n",
    "   - **Internal steps**: Use DiscoveryAgent to find `main.py`. Use DiscoveryAgent to find `backend`. If both found, delegate to RelationResolverAgent. If any missing, inform user.\n",
    "\n",
    "4. **Query**: \"What does `database.py` depend on?\"\n",
    "   - **Plan for user**: Okay, I understand the query. I will first search to locate the `database.py` file and then determine its dependencies.\n",
    "   - **Internal steps**: Use DiscoveryAgent to find `database.py`. If found, use RelationResolverAgent to get its dependencies. Do not return Discovery result alone.\n",
    "\n",
    "5. **Query**: \"What is the full path to `main.py`?\"\n",
    "   - **Plan for user**: Okay, I understand the query. I will first search to locate the `main.py` file and then determine its full path.\n",
    "   - **Internal steps**: Use DiscoveryAgent to find `main.py`. If found, delegate to RelationResolverAgent. Do NOT try to calculate the path yourself.\n",
    "\n",
    "Think like a software engineer. Verify, reason, then respond. Focus on *what* you are doing for the user, not *which internal tool* you are using.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# The planner_agent definition remains the same, only the system_prompt is updated\n",
    "planner_agent = FunctionAgent(\n",
    "   name=\"PlannerAgent\",\n",
    "   description=\"The strategic reasoning core that analyzes user queries, breaks them into subtasks, delegates to specialized agents, and synthesizes the final response.\",\n",
    "   tools=[], \n",
    "   llm=llm_gemini, \n",
    "   system_prompt=PLANNER_PROMPT,\n",
    "   can_handoff_to=[\"ResearcherAgent\", \"RelationResolverAgent\", \"DiscoveryAgent\"] # Using 'can_handoff_to'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import AgentWorkflow\n",
    "\n",
    "insight_agent=AgentWorkflow(\n",
    "    agents=[planner_agent,discovery_agent, research_agent, relre_agent],\n",
    "    root_agent=planner_agent.name,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🤖 Agent: PlannerAgent\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I understand the query. I will first search to locate the `main` file and the `utils` file, and then investigate the relationship between them.\n",
      "\n",
      "📤 Output: Okay, I understand the query. I will first search to locate the `main` file and the `utils` file, and then investigate the relationship between them.\n",
      "\n",
      "\n",
      "🛠️  Planning to use tools: ['handoff']\n",
      "\n",
      "==================================================\n",
      "🤖 Agent: DiscoveryAgent\n",
      "==================================================\n",
      "\n",
      "🛠️  Planning to use tools: ['extract_node']\n",
      "🛠️  Planning to use tools: ['search_graph']\n",
      "🛠️  Planning to use tools: ['extract_node']\n",
      "🛠️  Planning to use tools: ['search_graph']\n",
      "[DiscoveryAgent Response]\n",
      "- **Entity**: `main.py` (Type: File)\n",
      "- **Reason**: main file is related to utils file because it imports and uses functions from it.\n",
      "- **Search Results**:\n",
      "  - **Node**: main.py\n",
      "  - **Node**: utils.py\n",
      "    **Description**: utils.py includes functions for handling image files, specifically for processing delivery images using OCR.  The core functionality revolves around saving uploaded image files, loading them, and then using a generative AI model to extract a delivery summary based on a predefined prompt. The `process_delivery_image` function orchestrates the entire OCR pipeline, from saving the image to extracting and returning the delivery summary.\n",
      "\n",
      "📤 Output: [DiscoveryAgent Response]\n",
      "- **Entity**: `main.py` (Type: File)\n",
      "- **Reason**: main file is related to utils file because it imports and uses functions from it.\n",
      "- **Search Results**:\n",
      "  - **Node**: main.py\n",
      "  - **Node**: utils.py\n",
      "    **Description**: utils.py includes functions for handling image files, specifically for processing delivery images using OCR.  The core functionality revolves around saving uploaded image files, loading them, and then using a generative AI model to extract a delivery summary based on a predefined prompt. The `process_delivery_image` function orchestrates the entire OCR pipeline, from saving the image to extracting and returning the delivery summary.\n",
      "\n",
      "\n",
      "🛠️  Planning to use tools: ['handoff']\n",
      "\n",
      "==================================================\n",
      "🤖 Agent: PlannerAgent\n",
      "==================================================\n",
      "\n",
      "The `main.py` file is related to the `utils.py` file because it imports and uses functions from `utils.py`, specifically for handling image files and processing delivery images using OCR.  The `utils.py` file provides the core functionality for saving, loading, and processing images, which is then utilized by the `main.py` file to extract delivery information.\n",
      "📤 Output: The `main.py` file is related to the `utils.py` file because it imports and uses functions from `utils.py`, specifically for handling image files and processing delivery images using OCR.  The `utils.py` file provides the core functionality for saving, loading, and processing images, which is then utilized by the `main.py` file to extract delivery information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "handler = insight_agent.run(\n",
    "    user_msg=\" how main file related to utils file?\"\n",
    ")\n",
    "\n",
    "current_agent = None\n",
    "current_tool_calls = \"\"\n",
    "async for event in handler.stream_events():\n",
    "    if (\n",
    "        hasattr(event, \"current_agent_name\")\n",
    "        and event.current_agent_name != current_agent\n",
    "    ):\n",
    "        current_agent = event.current_agent_name\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"🤖 Agent: {current_agent}\")\n",
    "        print(f\"{'='*50}\\n\")\n",
    "    elif isinstance(event, AgentStream):\n",
    "        print(event.delta, end=\"\", flush=True)\n",
    "    \n",
    "    elif isinstance(event, AgentOutput):\n",
    "        if event.response.content:\n",
    "            print(\"📤 Output:\", event.response.content)\n",
    "        if event.tool_calls:\n",
    "            print(\n",
    "                \"🛠️  Planning to use tools:\",\n",
    "                [call.tool_name for call in event.tool_calls],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
